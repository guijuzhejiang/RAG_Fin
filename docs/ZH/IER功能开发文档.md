# IER åŠŸèƒ½å¼€å‘æ–‡æ¡£

## ç›®æ ‡æ¦‚è¿°

åœ¨ç°æœ‰çš„ RAG ç³»ç»Ÿä¸Šæ–°å¢ä¸€ä¸ªæ¨¡å—ï¼Œæ”¯æŒï¼š

ä¸€. æ–‡ä»¶è§£æé˜¶æ®µ
1. åœ¨çŸ¥è¯†åº“ä¸­ä»…ä¸Šä¼ å¹¶è§£æå•ä¸ª IER çš„ PDF æ–‡æ¡£ã€‚(åœ¨ç”»é¢æ‰‹åŠ¨å®Œæˆï¼Œæ— éœ€ä¿®æ”¹ä»£ç )
2. ä½¿ç”¨ ChatLLMï¼ˆæœ¬åœ°ollamaéƒ¨ç½²çš„LLMï¼‰è§£æ IER PDF å¹¶æŠ½å–ä¸‰ä¸ªæ ¸å¿ƒå­—æ®µï¼š`industry`ï¼ˆå¯èƒ½å¤šä¸ªï¼‰ã€`Geography`ï¼ˆå¯èƒ½å¤šä¸ªï¼‰ã€ä»¥åŠæ–‡æ¡£`æ¦‚è¦`ï¼ˆsummaryï¼‰ã€‚å¯å‚è€ƒï¼š[extract_IER_summary.py](..%2F..%2Frag%2Fnlp%2Fextract_IER_summary.py)
3. æ–°å»ºæ•°æ®åº“è¡¨ `IER`ï¼Œå‘è¡¨ä¸­æ’å…¥ï¼š`kb_id`ï¼ˆçŸ¥è¯†åº“IDï¼‰ã€`pdf_filename`ã€`industries`ã€`geographies`ã€`summary`ã€ä»¥åŠå…ƒæ•°æ®å­—æ®µï¼ˆå¦‚ `id`ã€`create_time`ã€`create_date`ã€`update_time`ã€`update_date` ç­‰ï¼‰ã€‚
4. ä½¿ç”¨ç°æœ‰é€»è¾‘ä»£ç [pdf_parser_docling_VLM.py](..%2F..%2Fdeepdoc%2Fparser%2Fpdf_parser_docling_VLM.py)è§£æpdfæ–‡æ¡£å¹¶å†™å…¥çŸ¥è¯†åº“ï¼ˆå·²æœ‰åŠŸèƒ½ï¼‰ã€‚

äºŒ. ç”¨æˆ·é—®ç­”é˜¶æ®µ
1. å½“ç”¨æˆ·æé—®æ—¶ï¼Œç”¨æˆ·å…ˆæŒ‡å®šä¸‰ä¸ªæŸ¥è¯¢æ¡ä»¶ï¼š`industry`ã€`Geography`ã€`é—®é¢˜æ¦‚è¦`ï¼›éšåä»¥è¿™äº›æ¡ä»¶å¯¹ `IER` è¡¨åšæ¨¡ç³Šæˆ–ç›¸ä¼¼åº¦åŒ¹é…ï¼Œè¿”å›æ£€ç´¢åŒ¹é…åˆ°çš„å¤šä¸ª `kb_id`ã€‚
2. å‰ç«¯ç”¨æˆ·åœ¨åˆšæ£€ç´¢åˆ°çš„å¤šä¸ª`kb_id`ä¸­é€‰æ‹©ä¸€ä¸ªï¼Œç‚¹å‡»"æ£€ç´¢"ï¼Œå‘é€ç»™åç«¯ä¸€ä¸ªæŒ‡å®šçš„`kb_id`ï¼Œ åç«¯ä½¿ç”¨è¯¥çŸ¥è¯†åº“ä½œä¸ºRAGçš„æ£€ç´¢æ¥æºï¼Œæ‰§è¡Œ RAG é—®ç­”å¹¶è¿”å›ç»™ç”¨æˆ·ã€‚
3. ç°æœ‰RAGæœåŠ¡ç³»ç»Ÿæ¡†æ¶æˆ–åŠŸèƒ½ä»£ç æ— éœ€æ”¹å˜ï¼Œåªå¢åŠ ä¸Šé¢çš„æåˆ°åŠŸèƒ½ï¼Œå¹¶ä¸”åšæœ€å°çš„æ”¹åŠ¨ã€‚
4. åªè´Ÿè´£ä¿®æ”¹åç«¯ä»£ç ï¼Œä¸ä¿®æ”¹å‰ç«¯ä»£ç ã€‚

---

## æ€»ä½“æ¶æ„ï¼ˆé«˜å±‚ï¼‰

* **è§£ææœåŠ¡ï¼ˆIngest Serviceï¼‰**ï¼šè§£æä»»åŠ¡è°ƒç”¨ ChatLLM æå–ç»“æ„åŒ–å­—æ®µå¹¶å†™å…¥ `IER` è¡¨ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰ï¼Œç„¶åè§£æpdfæ–‡æ¡£å†…å®¹å†™å…¥çŸ¥è¯†åº“ï¼ˆå·²æœ‰åŠŸèƒ½ï¼‰ã€‚
* **æ•°æ®åº“**ï¼šæ–°å¢ `IER` è¡¨ï¼ŒçŸ¥è¯†åº“å…ƒæ•°æ®è¡¨ï¼ˆå·²æœ‰ï¼‰ä¿æŒä¸å˜ä½†éœ€ä¿è¯ `kb_id` å¯è¢«å…³è”ã€‚
* **æŸ¥è¯¢æœåŠ¡ï¼ˆUser Query Serviceï¼‰**ï¼šå‰ç«¯ç”¨æˆ·å‘é€æ£€ç´¢æ¡ä»¶ï¼ˆindustryã€Geographyã€é—®é¢˜æ¦‚è¦ï¼‰ï¼ŒæœåŠ¡ä½¿ç”¨æ¨¡ç³ŠåŒ¹é… / å‘é‡ç›¸ä¼¼åº¦æˆ–å…¨æ–‡æœç´¢åœ¨ `IER` è¡¨ä¸­æ£€ç´¢ç›¸å…³ `kb_id`ã€‚
* **RAG æœåŠ¡**ï¼šä½¿ç”¨ç”¨æˆ·æŒ‡å®šæ£€ç´¢åˆ°çš„çŸ¥è¯†åº“ id çš„å†…å®¹ä½œä¸ºæ£€ç´¢å€™é€‰ï¼Œç»“åˆ ChatLLM ç”Ÿæˆæœ€ç»ˆå›ç­”ï¼ˆå·²æœ‰åŠŸèƒ½ï¼‰ã€‚

---

## æ•°æ®åº“è®¾è®¡ï¼ˆå»ºè®®ä½¿ç”¨æœ¬åœ°ç°æœ‰æ•°æ®åº“mysql æˆ– ElasticSearchï¼‰ï¼Œä»”ç»†è€ƒè™‘å“ªç§æ–¹æ¡ˆå¯è¡Œ

### æ–¹æ¡ˆ Aï¼šæœ¬åœ°ç°æœ‰æ•°æ®åº“mysql

> è¯´æ˜ï¼š`industries` ä¸ `geographies`ä½œä¸ºæ•°ç»„å­—æ®µï¼Œä¾¿äºå­˜å‚¨å¤šä¸ªå€¼ã€‚ä¸ºäº†åšæ¨¡ç³Š/ç›¸ä¼¼åŒ¹é…ï¼Œä½¿ç”¨å…¨æ–‡æœç´¢æˆ–å‘é‡ç›¸ä¼¼åº¦æœ€å¥½ã€‚

### æ–¹æ¡ˆ Bï¼šElasticSearch

* å°† `IER` æ–‡æ¡£ç´¢å¼•åˆ° ESï¼Œ`industries` ä¸ `geographies` ä½¿ç”¨ keyword + text åŒå­—æ®µï¼Œ`summary` ä½¿ç”¨ `text` å¹¶å¼€å¯ `nGram` æˆ– `edge_ngram` åˆ†è¯ä»¥ä¾¿æ¨¡ç³ŠåŒ¹é…ã€‚
* ES æ›´é€‚åˆé«˜å¹¶å‘ã€æ¨¡ç³Šæœç´¢å’Œå¤æ‚ç›¸ä¼¼åº¦æŸ¥è¯¢ã€‚

---

## è§£æï¼ˆExtractionï¼‰æµç¨‹ä¸ ChatLLM Prompt è§„èŒƒ


### ChatLLM æå– è¿”å›

> ç¤ºä¾‹ï¼š

```json
{
  "industries": ["åŠå¯¼ä½“","ç”µå­åˆ¶é€ "],
  "geographies": ["ä¸­å›½","ä¸œå—äºš"],
  "summary": "æœ¬æŠ¥å‘Šåˆ†æäº†ä¸­å›½å’Œä¸œå—äºšå¸‚åœºçš„åŠå¯¼ä½“ä¾›åº”é“¾ï¼ŒæŒ‡å‡ºçŸ­æœŸå†…äº§èƒ½ç´§å¼ ï¼Œä½†é•¿è¿œçœ‹å—ç›Šäºæ”¿ç­–æ”¯æŒä¸æŠ•èµ„å¢é•¿ã€‚"
}
```

---

## IERåŠŸèƒ½å®ç°è¿›åº¦ - 2025å¹´1æœˆ2æ—¥æ›´æ–°

### âœ… å·²å®Œæˆçš„æ ¸å¿ƒåŠŸèƒ½

#### 1. æ•°æ®åº“æ¨¡å‹å®ç° - æ··åˆæ¶æ„æ–¹æ¡ˆ

**æ–‡ä»¶**: `api/db/db_models.py`

é‡‡ç”¨äº†**æ··åˆMySQL + ElasticSearch**æ¶æ„ï¼š
- **MySQL**: å­˜å‚¨IERç»“æ„åŒ–æ•°æ®ï¼Œæ”¯æŒACIDäº‹åŠ¡
- **ElasticSearch**: ç´¢å¼•IERå­—æ®µï¼Œæ”¯æŒé«˜æ€§èƒ½æœç´¢

```python
class IerDocument(DataBaseModel):
    id = CharField(max_length=32, primary_key=True)
    document_id = CharField(max_length=32, null=False, help_text="Reference to document table", index=True)
    kb_id = CharField(max_length=256, null=False, help_text="Reference to knowledgebase", index=True)
    
    # IER fields (Industry, Geography, Summary) - è‹±æ–‡å­—æ®µå
    industry = CharField(max_length=255, null=True, help_text="Industry classification", index=True)
    geography = CharField(max_length=255, null=True, help_text="Geographic location/region", index=True)
    summary = LongTextField(null=True, help_text="Document summary")
    
    # Extraction metadata - æå–å…ƒæ•°æ®
    extraction_method = CharField(max_length=64, null=True, help_text="Method used for extraction", default="llm", index=True)
    extraction_model = CharField(max_length=128, null=True, help_text="Model used for extraction", index=True)
    extraction_confidence = FloatField(default=0.0, help_text="Confidence score for extraction")
    extraction_time = DateTimeField(null=True, help_text="When extraction was performed", index=True)
    
    # Additional structured data - é¢å¤–ç»“æ„åŒ–æ•°æ®
    metadata = JSONField(null=True, default={}, help_text="Additional extraction metadata")
```

#### 2. ElasticSearchæ˜ å°„é…ç½®

**æ–‡ä»¶**: `conf/mapping.json`

æ·»åŠ äº†ä¸“é—¨çš„IERå­—æ®µåŠ¨æ€æ¨¡æ¿ï¼š

```json
{
  "industry": {
    "match": "*_industry",
    "mapping": {
      "type": "keyword",
      "similarity": "boolean",
      "store": true,
      "fields": {
        "analyzed": {
          "type": "text",
          "analyzer": "whitespace",
          "store": true
        }
      }
    }
  }
},
{
  "geography": {
    "match": "*_geography", 
    "mapping": {
      "type": "keyword",
      "similarity": "boolean",
      "store": true,
      "fields": {
        "analyzed": {
          "type": "text",
          "analyzer": "whitespace",
          "store": true
        }
      }
    }
  }
},
{
  "summary": {
    "match": "*_summary",
    "mapping": {
      "type": "text",
      "similarity": "scripted_sim",
      "analyzer": "whitespace", 
      "store": true,
      "fields": {
        "keyword": {
          "type": "keyword",
          "store": true
        }
      }
    }
  }
}
```

**ç‰¹æ€§**:
- **Industry/Geography**: keywordç±»å‹æ”¯æŒç²¾ç¡®åŒ¹é…ï¼Œtextå­—æ®µæ”¯æŒæ¨¡ç³Šæœç´¢
- **Summary**: å…¨æ–‡æœç´¢ä¼˜åŒ–ï¼Œæ”¯æŒè„šæœ¬åŒ–ç›¸ä¼¼åº¦è¯„åˆ†
- **å­˜å‚¨ä¼˜åŒ–**: æ‰€æœ‰å­—æ®µå¯ç”¨storeä»¥æé«˜æ£€ç´¢æ€§èƒ½

#### 3. IERæœåŠ¡å±‚å®ç°

**æ–‡ä»¶**: `api/db/services/ier_service.py`

æä¾›å®Œæ•´çš„IERæ•°æ®CRUDæ“ä½œï¼š

```python
class IerService(CommonService):
    model = IerDocument

    @classmethod
    def get_by_document_id(cls, document_id):
        """æ ¹æ®æ–‡æ¡£IDè·å–IERè®°å½•"""
        
    @classmethod  
    def get_by_kb_id(cls, kb_id, page_number=1, items_per_page=10, 
                     orderby="extraction_time", desc=True, keywords=None):
        """æ ¹æ®çŸ¥è¯†åº“IDè·å–IERè®°å½•ï¼Œæ”¯æŒåˆ†é¡µå’Œå…³é”®è¯æœç´¢"""
        
    @classmethod
    def create_or_update(cls, document_id, kb_id, industry=None, geography=None, 
                        summary=None, extraction_method="llm", extraction_model=None, 
                        extraction_confidence=0.0, metadata=None):
        """åˆ›å»ºæˆ–æ›´æ–°IERè®°å½•"""

    @classmethod
    def search_by_industry(cls, industry_keywords, kb_ids=None, limit=50):
        """æŒ‰è¡Œä¸šå…³é”®è¯æœç´¢IERè®°å½•"""
        
    @classmethod
    def search_by_geography(cls, geography_keywords, kb_ids=None, limit=50):
        """æŒ‰åœ°ç†ä½ç½®å…³é”®è¯æœç´¢IERè®°å½•"""
        
    @classmethod
    def get_industry_stats(cls, kb_id=None):
        """è·å–è¡Œä¸šåˆ†å¸ƒç»Ÿè®¡"""
        
    @classmethod  
    def get_geography_stats(cls, kb_id=None):
        """è·å–åœ°ç†åˆ†å¸ƒç»Ÿè®¡"""
        
    @classmethod
    def get_documents_without_ier(cls, kb_id, limit=100):
        """è·å–å°šæœªè¿›è¡ŒIERæå–çš„æ–‡æ¡£"""
```

**æ ¸å¿ƒåŠŸèƒ½**:
- **å®Œæ•´CRUD**: æ”¯æŒIERæ•°æ®çš„å¢åˆ æ”¹æŸ¥
- **é«˜çº§æœç´¢**: åŸºäºindustry/geographyçš„æ¨¡ç³Šæœç´¢
- **ç»Ÿè®¡åˆ†æ**: æä¾›è¡Œä¸šã€åœ°ç†åˆ†å¸ƒç»Ÿè®¡
- **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡æ›´æ–°å’ŒæŸ¥è¯¢

#### 4. IERå­—æ®µæå–é€»è¾‘

**æ–‡ä»¶**: `api/db/services/ier_extraction.py`

åŸºäºChatLLMçš„æ™ºèƒ½å­—æ®µæå–ï¼š

```python
class IerExtractor:
    """
    IER (Industry, Geography, Summary) extraction using ChatLLM
    Analyzes document content to extract structured business information
    """
    
    def __init__(self, tenant_id: str, chat_model: str = None):
        """åˆå§‹åŒ–IERæå–å™¨ï¼Œä½¿ç”¨ChatLLM"""
        self.tenant_id = tenant_id
        self.chat_model = LLMBundle(tenant_id, LLMType.CHAT, chat_model, lang="English")
        
    def extract_from_content(self, content: str, max_content_length: int = 8000) -> Dict:
        """ä»æ–‡æ¡£å†…å®¹ä¸­æå–IERå­—æ®µ"""
        
    def extract_from_chunks(self, chunks: List[str], aggregate_method: str = "highest_confidence") -> Dict:
        """ä»å¤šä¸ªæ–‡æ¡£å—ä¸­æå–å¹¶èšåˆIERç»“æœ"""
```

**ä¸“é—¨ä¼˜åŒ–çš„æå–æç¤º**:
```python
self.extraction_prompt = """
You are an expert business document analyzer. Analyze the following document content and extract three key pieces of information:

1. **Industry**: The primary industry or business sector this document relates to. Be specific (e.g., "Financial Services", "Healthcare Technology", "Renewable Energy", "E-commerce").

2. **Geography**: The primary geographic location or market this document focuses on. This could be a country, region, city, or market area (e.g., "United States", "Asia-Pacific", "European Union", "Global").

3. **Summary**: A concise 2-3 sentence summary capturing the main business purpose, key findings, or primary focus of the document.

**Document Content:**
{content}

**Instructions:**
- If any field cannot be determined from the content, respond with "Unknown"
- Keep industry classifications specific but not overly granular
- For geography, prefer broader regions over specific cities unless the city is the clear focus
- Summary should be business-focused and factual
- Respond ONLY in the following JSON format:

```json
{{
    "industry": "specific industry classification",
    "geography": "primary geographic focus", 
    "summary": "concise business summary",
    "confidence": 0.85
}}
```
"""
```

**æ ¸å¿ƒç‰¹æ€§**:
- **è‹±æ–‡ä¼˜åŒ–**: ä¸“é—¨é’ˆå¯¹è‹±æ–‡å•†ä¸šæ–‡æ¡£ä¼˜åŒ–
- **ç»“æ„åŒ–è¾“å‡º**: å¼ºåˆ¶JSONæ ¼å¼è¾“å‡ºï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§
- **ç½®ä¿¡åº¦è¯„åˆ†**: æ¯æ¬¡æå–éƒ½åŒ…å«ç½®ä¿¡åº¦è¯„ä¼°
- **å¤šå—èšåˆ**: æ”¯æŒå¤šç§èšåˆç­–ç•¥ï¼ˆæœ€é«˜ç½®ä¿¡åº¦ã€å¤šæ•°æŠ•ç¥¨ã€æ™ºèƒ½ç»„åˆï¼‰
- **é”™è¯¯å¤„ç†**: å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œé™çº§ç­–ç•¥

#### 5. ElasticSearchç´¢å¼•ç®¡ç†

**æ–‡ä»¶**: `api/db/services/ier_indexing.py`

ç®¡ç†IERæ•°æ®åœ¨ESä¸­çš„ç´¢å¼•å’Œæœç´¢ï¼š

```python
class IerIndexManager:
    """
    Manages IER field indexing in ElasticSearch
    Synchronizes IER data between MySQL and ES
    """
    
    @staticmethod
    def index_ier_fields(tenant_id: str, doc_id: str, ier_data: dict):
        """å°†IERå­—æ®µç´¢å¼•åˆ°ElasticSearch"""
        
    @staticmethod
    def search_by_ier_fields(tenant_id: str, industry: str = None, geography: str = None, 
                           summary_keywords: str = None, confidence_threshold: float = 0.0, 
                           size: int = 50):
        """åŸºäºIERå­—æ®µåœ¨ElasticSearchä¸­æœç´¢æ–‡æ¡£"""
        
    @staticmethod
    def sync_ier_to_es(kb_id: str, tenant_id: str, limit: int = 100):
        """åŒæ­¥IERæ•°æ®ä»MySQLåˆ°ElasticSearch"""

def extract_and_index_ier(document_id: str, kb_id: str, content_chunks: list, 
                         tenant_id: str, chat_model: str = None) -> bool:
    """å®Œæ•´çš„IERæå–å’Œç´¢å¼•å·¥ä½œæµ"""
```

**æ ¸å¿ƒåŠŸèƒ½**:
- **åŒå†™æ¶æ„**: è‡ªåŠ¨åŒæ­¥MySQLå’ŒESæ•°æ®
- **é«˜çº§æœç´¢**: æ”¯æŒå¤åˆIERæ¡ä»¶æŸ¥è¯¢
- **æ‰¹é‡åŒæ­¥**: æ”¯æŒå†å²æ•°æ®æ‰¹é‡åŒæ­¥
- **æ€§èƒ½ä¼˜åŒ–**: ESç´¢å¼•ä¼˜åŒ–å’ŒæŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

#### 6. æ–‡æ¡£å¤„ç†æµç¨‹é›†æˆ

**æ–‡ä»¶**: `rag/svr/task_executor.py`

å°†IERæå–é›†æˆåˆ°æ–‡æ¡£å¤„ç†ä¸»æµç¨‹ï¼š

```python
# IER extraction for document after successful processing
try:
    from api.db.services.ier_indexing import extract_and_index_ier
    
    # Extract content chunks for IER analysis
    content_chunks = [c.get("content_with_weight", "") for c in cks if c.get("content_with_weight")]
    
    if content_chunks:
        ier_success = extract_and_index_ier(
            document_id=r["doc_id"],
            kb_id=r["kb_id"], 
            content_chunks=content_chunks,
            tenant_id=r["tenant_id"],
            chat_model=r.get("llm_id")  # Use tenant's default chat model
        )
        
        if ier_success:
            cron_logger.info(f"IER extraction and indexing completed for document {r['doc_id']}")
        else:
            cron_logger.warning(f"IER extraction and indexing failed for document {r['doc_id']}")
    else:
        cron_logger.warning(f"No content available for IER extraction for document {r['doc_id']}")
        
except Exception as e:
    # IER extraction failure should not stop document processing
    cron_logger.error(f"IER extraction error for document {r['doc_id']}: {str(e)}")
    traceback.print_exc()
```

**é›†æˆç‰¹æ€§**:
- **å¼‚æ­¥å¤„ç†**: IERæå–ä¸é˜»å¡æ–‡æ¡£å¤„ç†ä¸»æµç¨‹
- **é”™è¯¯éš”ç¦»**: IERå¤±è´¥ä¸å½±å“æ–‡æ¡£æ­£å¸¸å¤„ç†
- **è‡ªåŠ¨è§¦å‘**: æ–‡æ¡£å¤„ç†æˆåŠŸåè‡ªåŠ¨è§¦å‘IERæå–
- **å®Œæ•´æ—¥å¿—**: è¯¦ç»†çš„æ“ä½œæ—¥å¿—å’Œé”™è¯¯è·Ÿè¸ª

### ğŸ“Š å®Œæ•´æ•°æ®æµ

```
æ–‡æ¡£ä¸Šä¼  â†’ å†…å®¹è§£æ â†’ å‘é‡åŒ– â†’ ESç´¢å¼• â†’ âœ… IERæå– â†’ MySQLå­˜å‚¨ â†’ ESå­—æ®µæ›´æ–°
```

### ğŸ¯ æŠ€æœ¯å®ç°äº®ç‚¹

1. **æ··åˆæ¶æ„**: MySQLç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼ŒESæä¾›é«˜æ€§èƒ½æœç´¢
2. **è‹±æ–‡ä¼˜åŒ–**: é’ˆå¯¹è‹±æ–‡å•†ä¸šæ–‡æ¡£ä¸“é—¨ä¼˜åŒ–çš„æå–é€»è¾‘
3. **æ™ºèƒ½èšåˆ**: å¤šç§ç­–ç•¥èšåˆå¤šå—æ–‡æ¡£çš„æå–ç»“æœ
4. **ç½®ä¿¡åº¦è¯„åˆ†**: æ¯æ¬¡æå–éƒ½åŒ…å«è´¨é‡è¯„ä¼°
5. **å®Œæ•´é›†æˆ**: æ— ç¼é›†æˆåˆ°ç°æœ‰æ–‡æ¡£å¤„ç†æµç¨‹
6. **é”™è¯¯å¤„ç†**: å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œé™çº§ç­–ç•¥
7. **æ€§èƒ½ä¼˜åŒ–**: ESç´¢å¼•ä¼˜åŒ–å’Œæ‰¹é‡å¤„ç†æ”¯æŒ

### â³ å¾…å®ç°åŠŸèƒ½

- **APIç«¯ç‚¹**: åˆ›å»ºRESTful APIç”¨äºIERåŠŸèƒ½çš„ç®¡ç†å’ŒæŸ¥è¯¢
- **å‰ç«¯é›†æˆ**: æä¾›å‰ç«¯ç•Œé¢æ”¯æŒIERæœç´¢å’Œç®¡ç†
- **æ‰¹é‡å¤„ç†**: æ”¯æŒå†å²æ–‡æ¡£çš„æ‰¹é‡IERæå–

### ğŸ“ ä½¿ç”¨ç¤ºä¾‹

```python
# æå–å•ä¸ªæ–‡æ¡£çš„IER
from api.db.services.ier_extraction import extract_ier_for_document

success = extract_ier_for_document(
    document_id="doc123",
    kb_id="kb456", 
    content_chunks=["Document content chunk 1", "Document content chunk 2"],
    tenant_id="tenant789"
)

# æ‰¹é‡æå–çŸ¥è¯†åº“çš„IER
from api.db.services.ier_extraction import batch_extract_ier_for_kb

result = batch_extract_ier_for_kb(
    kb_id="kb456",
    tenant_id="tenant789",
    limit=10
)

# åŸºäºIERå­—æ®µæœç´¢
from api.db.services.ier_indexing import IerIndexManager

results = IerIndexManager.search_by_ier_fields(
    tenant_id="tenant789",
    industry="Financial Services",
    geography="United States",
    confidence_threshold=0.7
)
```

IERå­—æ®µæå–é€»è¾‘å·²å®Œå…¨å®ç°å¹¶é›†æˆï¼ğŸ‰

### ğŸ”§ æ ¸å¿ƒå®ç°æ€»ç»“

#### å®Œæ•´çš„æ–‡æ¡£å¤„ç†æµç¨‹é›†æˆ

IERåŠŸèƒ½å·²å®Œå…¨é›†æˆåˆ°ç°æœ‰çš„RAGæ–‡æ¡£å¤„ç†æµç¨‹ä¸­ï¼š

**ä¸»è¦é›†æˆç‚¹**ï¼š
- **task_executor.py (rag/svr/)**: åœ¨æ–‡æ¡£å¤„ç†æˆåŠŸåè‡ªåŠ¨è§¦å‘IERæå–
- **naive.py (rag/app/)**: PDFè§£ææ—¶æ”¯æŒVLMæ¨¡å‹ä¼ é€’
- **IERæœåŠ¡å±‚**: å®Œæ•´çš„æ•°æ®è®¿é—®å’Œä¸šåŠ¡é€»è¾‘å±‚

**è‡ªåŠ¨åŒ–æµç¨‹**ï¼š
```
æ–‡æ¡£ä¸Šä¼  â†’ è§£æ â†’ åˆ†å— â†’ å‘é‡åŒ– â†’ ESç´¢å¼• â†’ âœ…è‡ªåŠ¨IERæå– â†’ MySQLå­˜å‚¨ â†’ ESå­—æ®µç´¢å¼•
```

#### æ··åˆæ•°æ®åº“æ¶æ„å®ç°

**MySQLå­˜å‚¨ç»“æ„** (`api/db/db_models.py`):
```python
class IerDocument(DataBaseModel):
    # æ ¸å¿ƒæ ‡è¯†å­—æ®µ
    id = CharField(max_length=32, primary_key=True)
    document_id = CharField(max_length=32, null=False, index=True)  # å…³è”documentè¡¨
    kb_id = CharField(max_length=256, null=False, index=True)       # å…³è”çŸ¥è¯†åº“
    
    # IERæ ¸å¿ƒå­—æ®µ (è‹±æ–‡å­—æ®µå)
    industry = CharField(max_length=255, null=True, index=True)     # è¡Œä¸šåˆ†ç±»
    geography = CharField(max_length=255, null=True, index=True)    # åœ°ç†ä½ç½®
    summary = LongTextField(null=True)                              # æ–‡æ¡£æ‘˜è¦
    
    # æå–å…ƒæ•°æ®
    extraction_method = CharField(max_length=64, default="llm", index=True)
    extraction_model = CharField(max_length=128, null=True, index=True)
    extraction_confidence = FloatField(default=0.0)                # ç½®ä¿¡åº¦è¯„åˆ†
    extraction_time = DateTimeField(null=True, index=True)         # æå–æ—¶é—´
    
    # æ‰©å±•ç»“æ„åŒ–æ•°æ®
    metadata = JSONField(null=True, default={})                    # é™„åŠ å…ƒæ•°æ®
```

**ElasticSearchç´¢å¼•ç»“æ„** (`conf/mapping.json`):
```json
{
  "industry": {
    "match": "*_industry",
    "mapping": {
      "type": "keyword",
      "similarity": "boolean",
      "store": true,
      "fields": {
        "analyzed": {
          "type": "text",
          "analyzer": "whitespace",
          "store": true
        }
      }
    }
  },
  "geography": {
    "match": "*_geography", 
    "mapping": {
      "type": "keyword",
      "similarity": "boolean",
      "store": true,
      "fields": {
        "analyzed": {
          "type": "text",
          "analyzer": "whitespace",
          "store": true
        }
      }
    }
  },
  "summary": {
    "match": "*_summary",
    "mapping": {
      "type": "text",
      "similarity": "scripted_sim",
      "analyzer": "whitespace", 
      "store": true,
      "fields": {
        "keyword": {
          "type": "keyword",
          "store": true
        }
      }
    }
  }
}
```

#### æ™ºèƒ½æå–ç®—æ³•

**ä¸“é—¨ä¼˜åŒ–çš„ChatLLMæç¤º** (`api/db/services/ier_extraction.py`):
- ğŸ¯ **è‹±æ–‡å•†ä¸šæ–‡æ¡£ä¸“é—¨ä¼˜åŒ–**
- ğŸ“Š **ç»“æ„åŒ–JSONè¾“å‡ºç¡®ä¿æ•°æ®ä¸€è‡´æ€§**
- ğŸšï¸ **ç½®ä¿¡åº¦è¯„åˆ†ç³»ç»Ÿ(0.0-1.0)**
- ğŸ”„ **å¤šç§èšåˆç­–ç•¥**: æœ€é«˜ç½®ä¿¡åº¦ã€å¤šæ•°æŠ•ç¥¨ã€æ™ºèƒ½ç»„åˆ
- âš ï¸ **å®Œæ•´é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥**

**æå–æ ¸å¿ƒé€»è¾‘**:
```python
self.extraction_prompt = """
You are an expert business document analyzer. Analyze the following document content and extract three key pieces of information:

1. **Industry**: The primary industry or business sector this document relates to. Be specific (e.g., "Financial Services", "Healthcare Technology", "Renewable Energy", "E-commerce").

2. **Geography**: The primary geographic location or market this document focuses on. This could be a country, region, city, or market area (e.g., "United States", "Asia-Pacific", "European Union", "Global").

3. **Summary**: A concise 2-3 sentence summary capturing the main business purpose, key findings, or primary focus of the document.

**Document Content:**
{content}

**Instructions:**
- If any field cannot be determined from the content, respond with "Unknown"
- Keep industry classifications specific but not overly granular
- For geography, prefer broader regions over specific cities unless the city is the clear focus
- Summary should be business-focused and factual
- Respond ONLY in the following JSON format:

```json
{{
    "industry": "specific industry classification",
    "geography": "primary geographic focus", 
    "summary": "concise business summary",
    "confidence": 0.85
}}
```

Confidence should be between 0.0 and 1.0, representing how confident you are in the extractions based on the content quality and clarity.
"""
```

#### é«˜çº§æœç´¢å’Œç´¢å¼•ç®¡ç†

**ElasticSearchç´¢å¼•ç®¡ç†** (`api/db/services/ier_indexing.py`):
- ğŸ”„ **åŒå†™æ¶æ„**: è‡ªåŠ¨åŒæ­¥MySQLå’ŒESæ•°æ®
- ğŸ” **é«˜çº§æœç´¢**: æ”¯æŒå¤åˆIERæ¡ä»¶æŸ¥è¯¢
- ğŸ“Š **æ‰¹é‡åŒæ­¥**: æ”¯æŒå†å²æ•°æ®æ‰¹é‡åŒæ­¥
- âš¡ **æ€§èƒ½ä¼˜åŒ–**: ESç´¢å¼•ä¼˜åŒ–å’ŒæŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

**æœç´¢åŠŸèƒ½ç¤ºä¾‹**:
```python
# åŸºäºIERå­—æ®µçš„å¤åˆæœç´¢
results = IerIndexManager.search_by_ier_fields(
    tenant_id="tenant123",
    industry="Financial Services",           # è¡Œä¸šè¿‡æ»¤
    geography="United States",               # åœ°ç†ä½ç½®è¿‡æ»¤
    summary_keywords="market analysis",      # æ‘˜è¦å…³é”®è¯æœç´¢
    confidence_threshold=0.7,                # æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼
    size=50                                  # è¿”å›ç»“æœæ•°é‡
)
```

#### å®é™…é›†æˆæ•ˆæœ

**æ–‡æ¡£å¤„ç†æµç¨‹è‡ªåŠ¨åŒ–** (`rag/svr/task_executor.py:394-420`):
```python
# IER extraction for document after successful processing
try:
    from api.db.services.ier_indexing import extract_and_index_ier
    
    # Extract content chunks for IER analysis
    content_chunks = [c.get("content_with_weight", "") for c in cks if c.get("content_with_weight")]
    
    if content_chunks:
        ier_success = extract_and_index_ier(
            document_id=r["doc_id"],
            kb_id=r["kb_id"], 
            content_chunks=content_chunks,
            tenant_id=r["tenant_id"],
            chat_model=r.get("llm_id")  # Use tenant's default chat model
        )
        
        if ier_success:
            cron_logger.info(f"IER extraction and indexing completed for document {r['doc_id']}")
        else:
            cron_logger.warning(f"IER extraction and indexing failed for document {r['doc_id']}")
    else:
        cron_logger.warning(f"No content available for IER extraction for document {r['doc_id']}")
        
except Exception as e:
    # IER extraction failure should not stop document processing
    cron_logger.error(f"IER extraction error for document {r['doc_id']}: {str(e)}")
    traceback.print_exc()
```

**å…³é”®ç‰¹æ€§**:
- âœ… **é”™è¯¯éš”ç¦»**: IERæå–å¤±è´¥ä¸å½±å“æ–‡æ¡£æ­£å¸¸å¤„ç†
- âœ… **è‡ªåŠ¨è§¦å‘**: æ–‡æ¡£å¤„ç†æˆåŠŸåè‡ªåŠ¨è§¦å‘IERæå–
- âœ… **å®Œæ•´æ—¥å¿—**: è¯¦ç»†çš„æ“ä½œæ—¥å¿—å’Œé”™è¯¯è·Ÿè¸ª
- âœ… **å¼‚æ­¥å¤„ç†**: IERæå–ä¸é˜»å¡ä¸»æµç¨‹

### ğŸ“ˆ æŠ€æœ¯åˆ›æ–°äº®ç‚¹

1. **ğŸ—ï¸ æ··åˆæ¶æ„è®¾è®¡**: MySQLç¡®ä¿ACIDäº‹åŠ¡ï¼ŒESæä¾›æ¯«ç§’çº§æœç´¢
2. **ğŸ§  æ™ºèƒ½èšåˆç®—æ³•**: å¤šç§ç­–ç•¥å¤„ç†å¤šå—æ–‡æ¡£çš„æå–ç»“æœ
3. **ğŸ“Š ç½®ä¿¡åº¦è¯„åˆ†ç³»ç»Ÿ**: æ¯æ¬¡æå–éƒ½åŒ…å«è´¨é‡è¯„ä¼°å’Œå¯ä¿¡åº¦
4. **ğŸ”„ åŒå†™åŒæ­¥æœºåˆ¶**: å®æ—¶ä¿æŒMySQLå’ŒESæ•°æ®ä¸€è‡´æ€§
5. **âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥**: ESç´¢å¼•ä¼˜åŒ–ã€æ‰¹é‡å¤„ç†ã€æ™ºèƒ½ç¼“å­˜
6. **ğŸ›¡ï¸ å®Œæ•´é”™è¯¯å¤„ç†**: å¼‚å¸¸éš”ç¦»ã€é™çº§ç­–ç•¥ã€è¯¦ç»†æ—¥å¿—

### ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

**ä¸šåŠ¡æŸ¥è¯¢ç¤ºä¾‹**:
```python
# åœºæ™¯1: æŸ¥æ‰¾æ‰€æœ‰é‡‘èæœåŠ¡è¡Œä¸šçš„ç¾å›½å¸‚åœºæ–‡æ¡£
financial_docs = IerIndexManager.search_by_ier_fields(
    tenant_id="corp123",
    industry="Financial Services",
    geography="United States",
    confidence_threshold=0.8
)

# åœºæ™¯2: æ‰¹é‡æå–å†å²æ–‡æ¡£çš„IERä¿¡æ¯
batch_result = batch_extract_ier_for_kb(
    kb_id="kb_finance_2024",
    tenant_id="corp123",
    limit=50
)

# åœºæ™¯3: è·å–è¡Œä¸šåˆ†å¸ƒç»Ÿè®¡
industry_stats = IerService.get_industry_stats(kb_id="kb_finance_2024")
geography_stats = IerService.get_geography_stats(kb_id="kb_finance_2024")
```

**æ•°æ®è´¨é‡ä¿è¯**:
- ğŸ“Š **ç½®ä¿¡åº¦è¯„åˆ†**: æ¯æ¬¡æå–éƒ½æœ‰0.0-1.0çš„è´¨é‡è¯„åˆ†
- ğŸ” **å¤šé‡éªŒè¯**: å¤šç§èšåˆç­–ç•¥ç¡®ä¿æå–å‡†ç¡®æ€§
- ğŸ“ **è¯¦ç»†å…ƒæ•°æ®**: è®°å½•æå–æ–¹æ³•ã€æ¨¡å‹ã€æ—¶é—´ç­‰å®Œæ•´ä¿¡æ¯
- ğŸ”„ **é‡æ–°æå–**: æ”¯æŒå¯¹ä½è´¨é‡æå–ç»“æœé‡æ–°å¤„ç†

IERåŠŸèƒ½å®ç°äº†ä»æ–‡æ¡£è‡ªåŠ¨è§£æåˆ°æ™ºèƒ½æœç´¢çš„å®Œæ•´é—­ç¯ï¼ğŸš€
